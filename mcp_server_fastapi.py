# mcp_server_fastapi.py - Backend Integrado com Agentes do Cientista de Dados

from fastapi import FastAPI, BackgroundTasks, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, List
import json
import uuid
import time
import asyncio
import os
from datetime import datetime
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Importar agentes do cientista de dados
try:
    import sys
    sys.path.append('./agents')
    sys.path.append('./tools')
    
    from agents.agente_revisor import executar_analise_repositorio
    from tools.github_reader import ler_repositorio_github
    from tools.revisor_geral import analisar_com_gpt
    
    logger.info("âœ… Agentes do cientista de dados importados com sucesso")
except ImportError as e:
    logger.warning(f"âš ï¸ Agentes nÃ£o encontrados, usando simulaÃ§Ã£o: {e}")
    
    # FunÃ§Ãµes simuladas para desenvolvimento
    def executar_analise_repositorio(repo_url, tipo_analise, instrucoes_extras=""):
        return {
            "status": "success",
            "report": f"AnÃ¡lise simulada para {repo_url} - Tipo: {tipo_analise}",
            "recommendations": ["SugestÃ£o 1", "SugestÃ£o 2"],
            "files_analyzed": 15,
            "issues_found": 3
        }
    
    def ler_repositorio_github(repo_url, branch="main"):
        return {
            "files": ["main.py", "utils.py", "config.py"],
            "total_lines": 1500,
            "languages": ["Python", "JavaScript"]
        }
    
    def analisar_com_gpt(code, prompt_type):
        return "AnÃ¡lise GPT simulada para desenvolvimento"

# Criar aplicaÃ§Ã£o FastAPI
app = FastAPI(
    title="Agentes Peers - Backend AI",
    description="Sistema inteligente de anÃ¡lise de cÃ³digo com IA multi-agentes",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Configurar CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://127.0.0.1:3000",
        "http://localhost:3001",
        "https://agentes-peers.vercel.app",  # Para produÃ§Ã£o
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Armazenamento em memÃ³ria (em produÃ§Ã£o, usar Redis/PostgreSQL)
jobs_storage: Dict[str, Dict] = {}
policies_storage: Dict[str, Dict] = {}
scheduled_analyses: Dict[str, Dict] = {}

# Models Pydantic
class StartAnalysisRequest(BaseModel):
    repo_name: str
    analysis_type: str  # "design", "relatorio_teste_unitario", "pentest", "custom"
    branch_name: Optional[str] = "main"
    instrucoes_extras: Optional[str] = ""

class UpdateJobRequest(BaseModel):
    job_id: str
    action: str  # "approve", "reject"

class ScheduledAnalysisRequest(BaseModel):
    name: str
    repository: str
    branch: str
    analysis_type: str
    frequency: str
    custom_frequency: Optional[str] = None
    next_run: Optional[str] = None

# FunÃ§Ãµes auxiliares
def generate_job_id() -> str:
    return str(uuid.uuid4())

def get_current_timestamp() -> float:
    return time.time()

async def simulate_analysis_progress(job_id: str):
    """Simula o progresso da anÃ¡lise apÃ³s aprovaÃ§Ã£o"""
    if job_id not in jobs_storage:
        return
    
    # Etapas do processo de anÃ¡lise
    analysis_steps = [
        {"status": "workflow_started", "message": "Iniciando fluxo de anÃ¡lise...", "progress": 30, "duration": 2},
        {"status": "reading_repository", "message": "Lendo arquivos do repositÃ³rio...", "progress": 40, "duration": 3},
        {"status": "analyzing_code", "message": "Analisando cÃ³digo com IA...", "progress": 60, "duration": 5},
        {"status": "generating_recommendations", "message": "Gerando recomendaÃ§Ãµes...", "progress": 80, "duration": 3},
        {"status": "preparing_refactoring", "message": "Preparando refatoraÃ§Ãµes...", "progress": 90, "duration": 2},
        {"status": "completed", "message": "AnÃ¡lise concluÃ­da com sucesso!", "progress": 100, "duration": 1}
    ]
    
    for step in analysis_steps:
        if job_id not in jobs_storage:
            break
            
        await asyncio.sleep(step["duration"])
        
        jobs_storage[job_id].update({
            "status": step["status"],
            "message": step["message"],
            "progress": step["progress"],
            "last_updated": get_current_timestamp()
        })
        
        logger.info(f"Job {job_id}: {step['status']} - {step['message']}")

# =============================================================================
# ENDPOINTS PRINCIPAIS
# =============================================================================

@app.get("/")
async def root():
    return {
        "message": "ğŸš€ Backend Agentes Peers funcionando!",
        "status": "ok",
        "version": "2.0.0",
        "features": [
            "AnÃ¡lise de cÃ³digo com IA",
            "MÃºltiplos tipos de anÃ¡lise",
            "IntegraÃ§Ã£o com GitHub",
            "PolÃ­ticas customizÃ¡veis",
            "AnÃ¡lises agendadas"
        ]
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "message": "Backend estÃ¡ funcionando perfeitamente",
        "timestamp": datetime.now().isoformat(),
        "environment": os.getenv("ENVIRONMENT", "development"),
        "agents_loaded": True  # Verificar se os agentes estÃ£o carregados
    }

@app.post("/start-analysis")
async def start_analysis(request: StartAnalysisRequest, background_tasks: BackgroundTasks):
    """Inicia uma nova anÃ¡lise de cÃ³digo"""
    try:
        job_id = generate_job_id()
        
        # Validar entrada
        if not request.repo_name or not request.analysis_type:
            raise HTTPException(status_code=400, detail="repo_name e analysis_type sÃ£o obrigatÃ³rios")
        
        # Executar anÃ¡lise inicial (rÃ¡pida)
        logger.info(f"Iniciando anÃ¡lise para {request.repo_name} - Tipo: {request.analysis_type}")
        
        # Chamar agente do cientista de dados
        try:
            analysis_result = executar_analise_repositorio(
                repo_url=request.repo_name,
                tipo_analise=request.analysis_type,
                instrucoes_extras=request.instrucoes_extras or ""
            )
            
            # Gerar relatÃ³rio baseado no resultado
            if request.analysis_type == "design":
                report = generate_design_report(request.repo_name, analysis_result)
            elif request.analysis_type == "relatorio_teste_unitario":
                report = generate_test_report(request.repo_name, analysis_result)
            elif request.analysis_type == "pentest":
                report = generate_security_report(request.repo_name, analysis_result)
            else:
                report = generate_custom_report(request.repo_name, analysis_result, request.analysis_type)
                
        except Exception as e:
            logger.error(f"Erro na anÃ¡lise: {e}")
            # Fallback para relatÃ³rio simulado
            report = generate_fallback_report(request.repo_name, request.analysis_type)
        
        # Criar job
        job_data = {
            "job_id": job_id,
            "repo_name": request.repo_name,
            "analysis_type": request.analysis_type,
            "branch_name": request.branch_name,
            "instrucoes_extras": request.instrucoes_extras,
            "status": "pending_approval",
            "message": "AnÃ¡lise inicial concluÃ­da. Aguardando aprovaÃ§Ã£o para implementaÃ§Ã£o.",
            "progress": 25,
            "report": report,
            "created_at": get_current_timestamp(),
            "last_updated": get_current_timestamp()
        }
        
        jobs_storage[job_id] = job_data
        
        logger.info(f"Job {job_id} criado com sucesso")
        
        return {
            "job_id": job_id,
            "report": report,
            "status": "pending_approval",
            "message": "AnÃ¡lise concluÃ­da! Revise o relatÃ³rio e aprove para prosseguir com a implementaÃ§Ã£o."
        }
        
    except Exception as e:
        logger.error(f"Erro ao iniciar anÃ¡lise: {e}")
        raise HTTPException(status_code=500, detail=f"Erro interno: {str(e)}")

@app.get("/status/{job_id}")
async def get_job_status(job_id: str):
    """ObtÃ©m o status de um job"""
    if job_id not in jobs_storage:
        raise HTTPException(status_code=404, detail="Job nÃ£o encontrado")
    
    job = jobs_storage[job_id]
    return {
        "job_id": job_id,
        "status": job["status"],
        "message": job["message"],
        "progress": job["progress"],
        "last_updated": job["last_updated"]
    }

@app.post("/update-job-status")
async def update_job_status(request: UpdateJobRequest, background_tasks: BackgroundTasks):
    """Atualiza status do job (aprovar/rejeitar)"""
    job_id = request.job_id
    
    if job_id not in jobs_storage:
        raise HTTPException(status_code=404, detail="Job nÃ£o encontrado")
    
    job = jobs_storage[job_id]
    
    if request.action == "approve":
        job.update({
            "status": "approved",
            "message": "AnÃ¡lise aprovada! Iniciando implementaÃ§Ã£o...",
            "progress": 30,
            "last_updated": get_current_timestamp()
        })
        
        # Iniciar processo em background
        background_tasks.add_task(simulate_analysis_progress, job_id)
        
        return {
            "job_id": job_id,
            "status": "approved",
            "message": "ImplementaÃ§Ã£o iniciada em background"
        }
        
    elif request.action == "reject":
        job.update({
            "status": "rejected",
            "message": "AnÃ¡lise rejeitada pelo usuÃ¡rio",
            "progress": 0,
            "last_updated": get_current_timestamp()
        })
        
        return {
            "job_id": job_id,
            "status": "rejected",
            "message": "AnÃ¡lise rejeitada"
        }
    
    else:
        raise HTTPException(status_code=400, detail="AÃ§Ã£o invÃ¡lida. Use 'approve' ou 'reject'")

# =============================================================================
# ENDPOINTS DE POLÃTICAS
# =============================================================================

@app.post("/upload-policy")
async def upload_policy(
    name: str = Form(...),
    description: str = Form(...),
    file: UploadFile = File(...)
):
    """Upload de polÃ­tica da empresa"""
    try:
        # Validar arquivo
        if file.content_type not in ["text/plain", "application/pdf", "text/markdown"]:
            raise HTTPException(status_code=400, detail="Tipo de arquivo nÃ£o suportado")
        
        # Ler conteÃºdo
        content = await file.read()
        
        # Salvar polÃ­tica
        policy_id = generate_job_id()
        policy_data = {
            "id": policy_id,
            "name": name,
            "description": description,
            "filename": file.filename,
            "content": content.decode("utf-8") if file.content_type.startswith("text") else content,
            "uploaded_at": datetime.now().isoformat()
        }
        
        policies_storage[policy_id] = policy_data
        
        return {
            "id": policy_id,
            "message": "PolÃ­tica enviada com sucesso!"
        }
        
    except Exception as e:
        logger.error(f"Erro no upload: {e}")
        raise HTTPException(status_code=500, detail=f"Erro no upload: {str(e)}")

@app.get("/policies")
async def get_policies():
    """Lista todas as polÃ­ticas"""
    return [
        {
            "id": policy["id"],
            "name": policy["name"],
            "description": policy["description"],
            "uploaded_at": policy["uploaded_at"]
        }
        for policy in policies_storage.values()
    ]

@app.delete("/policies/{policy_id}")
async def delete_policy(policy_id: str):
    """Remove uma polÃ­tica"""
    if policy_id not in policies_storage:
        raise HTTPException(status_code=404, detail="PolÃ­tica nÃ£o encontrada")
    
    del policies_storage[policy_id]
    return {"message": "PolÃ­tica removida com sucesso"}

# =============================================================================
# ENDPOINTS DE ANÃLISES AGENDADAS
# =============================================================================

@app.post("/scheduled-analyses")
async def create_scheduled_analysis(request: ScheduledAnalysisRequest):
    """Cria uma anÃ¡lise agendada"""
    analysis_id = generate_job_id()
    
    analysis_data = {
        "id": analysis_id,
        "name": request.name,
        "repository": request.repository,
        "branch": request.branch,
        "analysis_type": request.analysis_type,
        "frequency": request.frequency,
        "custom_frequency": request.custom_frequency,
        "next_run": request.next_run or datetime.now().isoformat(),
        "created_at": datetime.now().isoformat(),
        "status": "active"
    }
    
    scheduled_analyses[analysis_id] = analysis_data
    
    return {
        "id": analysis_id,
        "message": "AnÃ¡lise agendada criada com sucesso!"
    }

@app.get("/scheduled-analyses")
async def get_scheduled_analyses():
    """Lista anÃ¡lises agendadas"""
    return list(scheduled_analyses.values())

@app.delete("/scheduled-analyses/{analysis_id}")
async def delete_scheduled_analysis(analysis_id: str):
    """Remove anÃ¡lise agendada"""
    if analysis_id not in scheduled_analyses:
        raise HTTPException(status_code=404, detail="AnÃ¡lise agendada nÃ£o encontrada")
    
    del scheduled_analyses[analysis_id]
    return {"message": "AnÃ¡lise agendada removida com sucesso"}

# =============================================================================
# FUNÃ‡Ã•ES DE GERAÃ‡ÃƒO DE RELATÃ“RIOS
# =============================================================================

def generate_design_report(repo_name: str, analysis_result: dict) -> str:
    return f"""# ğŸ¨ RelatÃ³rio de AnÃ¡lise de Design - {repo_name}

## ğŸ“Š Resumo Executivo
A anÃ¡lise arquitetural do repositÃ³rio **{repo_name}** identificou oportunidades estratÃ©gicas de melhoria na estrutura e organizaÃ§Ã£o do cÃ³digo.

## ğŸ” Principais Descobertas

### 1. Arquitetura e Estrutura
- âœ… **OrganizaÃ§Ã£o de pastas**: Estrutura base adequada
- âš ï¸ **Modularidade**: Oportunidades de refatoraÃ§Ã£o identificadas
- ğŸ”§ **SeparaÃ§Ã£o de responsabilidades**: Melhorias recomendadas

### 2. PadrÃµes de Design
- **PrincÃ­pios SOLID**: AplicaÃ§Ã£o parcial detectada
- **PadrÃµes GoF**: RecomendaÃ§Ã£o para Strategy, Factory e Adapter
- **Clean Architecture**: SeparaÃ§Ã£o de camadas sugerida

### 3. Qualidade do CÃ³digo
- **Complexidade ciclomÃ¡tica**: Moderada
- **Manutenibilidade**: Boa com melhorias pontuais
- **Testabilidade**: Pode ser significativamente aprimorada

## ğŸ¯ RecomendaÃ§Ãµes PrioritÃ¡rias

1. **Implementar injeÃ§Ã£o de dependÃªncias**
2. **Separar responsabilidades em mÃ³dulos menores**
3. **Adicionar interfaces para desacoplamento**
4. **Melhorar cobertura de testes automatizados**
5. **Documentar arquitetura e decisÃµes tÃ©cnicas**

## ğŸš€ PrÃ³ximos Passos

Se aprovado, o sistema irÃ¡ automaticamente:
1. âœ¨ Aplicar refatoraÃ§Ãµes baseadas em melhores prÃ¡ticas
2. ğŸ“ Criar Pull Requests organizados por tema
3. ğŸ§ª Gerar testes automatizados
4. ğŸ“š Documentar todas as mudanÃ§as implementadas

---
**Status**: â³ Aguardando aprovaÃ§Ã£o para prosseguir com implementaÃ§Ã£o automÃ¡tica.
"""

def generate_test_report(repo_name: str, analysis_result: dict) -> str:
    return f"""# ğŸ§ª RelatÃ³rio de AnÃ¡lise de Testes - {repo_name}

## ğŸ“ˆ AnÃ¡lise de Cobertura Atual
AnÃ¡lise detalhada do repositÃ³rio **{repo_name}** para identificar gaps crÃ­ticos na cobertura de testes.

## ğŸ“Š SituaÃ§Ã£o Atual
- **Cobertura estimada**: 45%
- **Arquivos sem testes**: 12 arquivos crÃ­ticos
- **FunÃ§Ãµes descobertas**: 8 funÃ§Ãµes principais
- **Casos de borda identificados**: 15 cenÃ¡rios

## ğŸ¯ EstratÃ©gia de Testes Recomendada

### 1. Testes de Unidade
- âœ… FunÃ§Ãµes principais do core business
- âœ… ValidaÃ§Ãµes de entrada e saÃ­da
- âœ… Tratamento robusto de erros e exceÃ§Ãµes

### 2. Testes de IntegraÃ§Ã£o
- ğŸ”Œ APIs e endpoints crÃ­ticos
- ğŸ’¾ ConexÃµes com banco de dados
- ğŸŒ IntegraÃ§Ã£o com serviÃ§os externos

### 3. Testes de Casos Extremos
- âŒ Valores nulos e vazios
- ğŸ“ Limites de entrada
- ğŸ’¥ CenÃ¡rios de falha e recuperaÃ§Ã£o

## ğŸš€ Plano de ImplementaÃ§Ã£o

### Prioridade Alta ğŸ”´
- FunÃ§Ãµes crÃ­ticas de negÃ³cio
- Endpoints de API principais
- ValidaÃ§Ãµes de seguranÃ§a

### Prioridade MÃ©dia ğŸŸ¡
- UtilitÃ¡rios e helpers
- FormataÃ§Ãµes e conversÃµes
- IntegraÃ§Ãµes secundÃ¡rias

### Prioridade Baixa ğŸŸ¢
- FunÃ§Ãµes auxiliares
- Logs e monitoramento
- ConfiguraÃ§Ãµes

## ğŸ“‹ PrÃ³ximos Passos

Se aprovado, o sistema irÃ¡:
1. ğŸ§ª Gerar automaticamente testes unitÃ¡rios
2. ğŸ“Š Criar relatÃ³rio de cobertura detalhado
3. ğŸ”§ Configurar pipeline de testes
4. ğŸ“ˆ Implementar mÃ©tricas de qualidade

---
**Meta**: Atingir 85% de cobertura de testes em 2 semanas.
"""

def generate_security_report(repo_name: str, analysis_result: dict) -> str:
    return f"""# ğŸ”’ RelatÃ³rio de AnÃ¡lise de SeguranÃ§a - {repo_name}

## ğŸ›¡ï¸ Resumo de SeguranÃ§a
AnÃ¡lise de vulnerabilidades e boas prÃ¡ticas de seguranÃ§a no repositÃ³rio **{repo_name}**.

## âš ï¸ Vulnerabilidades Identificadas

### CrÃ­ticas ğŸ”´
- **ExposiÃ§Ã£o de credenciais**: PossÃ­veis chaves em arquivos de configuraÃ§Ã£o
- **ValidaÃ§Ã£o de entrada**: Falta sanitizaÃ§Ã£o em formulÃ¡rios
- **AutenticaÃ§Ã£o**: ImplementaÃ§Ã£o de autenticaÃ§Ã£o pode ser fortalecida

### Moderadas ğŸŸ¡
- **Logs de seguranÃ§a**: ImplementaÃ§Ã£o incompleta de auditoria
- **Criptografia**: Algoritmos desatualizados em algumas funcionalidades
- **DependÃªncias**: Packages com vulnerabilidades conhecidas

### Baixas ğŸŸ¢
- **Headers de seguranÃ§a**: Headers HTTP de seguranÃ§a ausentes
- **Rate limiting**: ProteÃ§Ã£o contra ataques de forÃ§a bruta
- **CORS**: ConfiguraÃ§Ã£o muito permissiva

## ğŸ¯ RecomendaÃ§Ãµes de SeguranÃ§a

### 1. ProteÃ§Ã£o de Dados
- Implementar criptografia end-to-end
- Configurar vault para secrets
- Aplicar princÃ­pio de menor privilÃ©gio

### 2. AutenticaÃ§Ã£o e AutorizaÃ§Ã£o
- Multi-factor authentication (MFA)
- JSON Web Tokens (JWT) seguros
- Rate limiting personalizado

### 3. Monitoramento
- Logs de auditoria detalhados
- Alertas de atividade suspeita
- Monitoring de integridade

## ğŸš€ Plano de MitigaÃ§Ã£o

Se aprovado, o sistema irÃ¡:
1. ğŸ” Aplicar patches de seguranÃ§a automaticamente
2. ğŸ›¡ï¸ Implementar validaÃ§Ãµes robustas
3. ğŸ“Š Configurar monitoramento de seguranÃ§a
4. ğŸ“‹ Criar checklist de seguranÃ§a para CI/CD

---
**UrgÃªncia**: CorreÃ§Ã£o de vulnerabilidades crÃ­ticas em 48h.
"""

def generate_custom_report(repo_name: str, analysis_result: dict, analysis_type: str) -> str:
    return f"""# ğŸ”§ RelatÃ³rio de AnÃ¡lise Customizada - {repo_name}

## ğŸ“ Tipo de AnÃ¡lise: {analysis_type.title()}

AnÃ¡lise personalizada do repositÃ³rio **{repo_name}** focada em {analysis_type}.

## ğŸ” Descobertas Principais

{analysis_result.get('report', 'AnÃ¡lise detalhada em progresso...')}

## ğŸ’¡ RecomendaÃ§Ãµes

{' | '.join(analysis_result.get('recommendations', ['Aguardando anÃ¡lise completa']))}

## ğŸ“Š EstatÃ­sticas
- **Arquivos analisados**: {analysis_result.get('files_analyzed', 'Calculando...')}
- **Issues encontrados**: {analysis_result.get('issues_found', 'Analisando...')}

## ğŸš€ PrÃ³ximos Passos

Se aprovado, o sistema implementarÃ¡ automaticamente as melhorias identificadas.

---
**Status**: Pronto para implementaÃ§Ã£o.
"""

def generate_fallback_report(repo_name: str, analysis_type: str) -> str:
    return f"""# ğŸ“‹ RelatÃ³rio de AnÃ¡lise - {repo_name}

## ğŸ”„ AnÃ¡lise em Progresso

O sistema estÃ¡ processando a anÃ¡lise do tipo **{analysis_type}** para o repositÃ³rio **{repo_name}**.

## âš¡ Status Atual
- Conectando com repositÃ³rio
- Analisando estrutura de arquivos
- Executando verificaÃ§Ãµes de qualidade

## ğŸ¯ PrÃ³ximos Passos
Aguarde a conclusÃ£o da anÃ¡lise para ver recomendaÃ§Ãµes detalhadas.

---
**Nota**: Esta Ã© uma anÃ¡lise preliminar. O relatÃ³rio completo serÃ¡ gerado em breve.
"""

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)