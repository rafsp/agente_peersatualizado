# mcp_server_fastapi.py - Backend Integrado com Agentes do Cientista de Dados

from fastapi import FastAPI, BackgroundTasks, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, List
import json
import uuid
import time
import asyncio
import os
from datetime import datetime
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Importar agentes do cientista de dados
try:
    import sys
    sys.path.append('./agents')
    sys.path.append('./tools')
    
    from agents.agente_revisor import executar_analise_repositorio
    from tools.github_reader import ler_repositorio_github
    from tools.revisor_geral import analisar_com_gpt
    
    logger.info("‚úÖ Agentes do cientista de dados importados com sucesso")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Agentes n√£o encontrados, usando simula√ß√£o: {e}")
    
    # Fun√ß√µes simuladas para desenvolvimento
    def executar_analise_repositorio(repo_url, tipo_analise, instrucoes_extras=""):
        return {
            "status": "success",
            "report": f"An√°lise simulada para {repo_url} - Tipo: {tipo_analise}",
            "recommendations": ["Sugest√£o 1", "Sugest√£o 2"],
            "files_analyzed": 15,
            "issues_found": 3
        }
    
    def ler_repositorio_github(repo_url, branch="main"):
        return {
            "files": ["main.py", "utils.py", "config.py"],
            "total_lines": 1500,
            "languages": ["Python", "JavaScript"]
        }
    
    def analisar_com_gpt(code, prompt_type):
        return "An√°lise GPT simulada para desenvolvimento"

# Criar aplica√ß√£o FastAPI
app = FastAPI(
    title="Agentes Peers - Backend AI",
    description="Sistema inteligente de an√°lise de c√≥digo com IA multi-agentes",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Configurar CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://127.0.0.1:3000",
        "http://localhost:3001",
        "https://agentes-peers.vercel.app",  # Para produ√ß√£o
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Armazenamento em mem√≥ria (em produ√ß√£o, usar Redis/PostgreSQL)
jobs_storage: Dict[str, Dict] = {}
policies_storage: Dict[str, Dict] = {}
scheduled_analyses: Dict[str, Dict] = {}

# Models Pydantic
class StartAnalysisRequest(BaseModel):
    repo_name: str
    analysis_type: str  # "design", "relatorio_teste_unitario", "pentest", "custom"
    branch_name: Optional[str] = "main"
    instrucoes_extras: Optional[str] = ""

class UpdateJobRequest(BaseModel):
    job_id: str
    action: str  # "approve", "reject"

class ScheduledAnalysisRequest(BaseModel):
    name: str
    repository: str
    branch: str
    analysis_type: str
    frequency: str
    custom_frequency: Optional[str] = None
    next_run: Optional[str] = None

# Fun√ß√µes auxiliares
def generate_job_id() -> str:
    return str(uuid.uuid4())

def get_current_timestamp() -> float:
    return time.time()

async def simulate_analysis_progress(job_id: str):
    """Simula o progresso da an√°lise ap√≥s aprova√ß√£o"""
    if job_id not in jobs_storage:
        return
    
    # Etapas do processo de an√°lise
    analysis_steps = [
        {"status": "workflow_started", "message": "Iniciando fluxo de an√°lise...", "progress": 30, "duration": 2},
        {"status": "reading_repository", "message": "Lendo arquivos do reposit√≥rio...", "progress": 40, "duration": 3},
        {"status": "analyzing_code", "message": "Analisando c√≥digo com IA...", "progress": 60, "duration": 5},
        {"status": "generating_recommendations", "message": "Gerando recomenda√ß√µes...", "progress": 80, "duration": 3},
        {"status": "preparing_refactoring", "message": "Preparando refatora√ß√µes...", "progress": 90, "duration": 2},
        {"status": "completed", "message": "An√°lise conclu√≠da com sucesso!", "progress": 100, "duration": 1}
    ]
    
    for step in analysis_steps:
        if job_id not in jobs_storage:
            break
            
        await asyncio.sleep(step["duration"])
        
        jobs_storage[job_id].update({
            "status": step["status"],
            "message": step["message"],
            "progress": step["progress"],
            "last_updated": get_current_timestamp()
        })
        
        logger.info(f"Job {job_id}: {step['status']} - {step['message']}")

# =============================================================================
# ENDPOINTS PRINCIPAIS
# =============================================================================

@app.get("/")
async def root():
    return {
        "message": "üöÄ Backend Agentes Peers funcionando!",
        "status": "ok",
        "version": "2.0.0",
        "features": [
            "An√°lise de c√≥digo com IA",
            "M√∫ltiplos tipos de an√°lise",
            "Integra√ß√£o com GitHub",
            "Pol√≠ticas customiz√°veis",
            "An√°lises agendadas"
        ]
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "message": "Backend est√° funcionando perfeitamente",
        "timestamp": datetime.now().isoformat(),
        "environment": os.getenv("ENVIRONMENT", "development"),
        "agents_loaded": True  # Verificar se os agentes est√£o carregados
    }

@app.post("/start-analysis")
async def start_analysis(request: StartAnalysisRequest, background_tasks: BackgroundTasks):
    """Inicia uma nova an√°lise de c√≥digo"""
    try:
        job_id = generate_job_id()
        
        # Validar entrada
        if not request.repo_name or not request.analysis_type:
            raise HTTPException(status_code=400, detail="repo_name e analysis_type s√£o obrigat√≥rios")
        
        # Executar an√°lise inicial (r√°pida)
        logger.info(f"Iniciando an√°lise para {request.repo_name} - Tipo: {request.analysis_type}")
        
        # Chamar agente do cientista de dados
        try:
            analysis_result = executar_analise_repositorio(
                repo_url=request.repo_name,
                tipo_analise=request.analysis_type,
                instrucoes_extras=request.instrucoes_extras or ""
            )
            
            # Gerar relat√≥rio baseado no resultado
            if request.analysis_type == "design":
                report = generate_design_report(request.repo_name, analysis_result)
            elif request.analysis_type == "relatorio_teste_unitario":
                report = generate_test_report(request.repo_name, analysis_result)
            elif request.analysis_type == "pentest":
                report = generate_security_report(request.repo_name, analysis_result)
            else:
                report = generate_custom_report(request.repo_name, analysis_result, request.analysis_type)
                
        except Exception as e:
            logger.error(f"Erro na an√°lise: {e}")
            # Fallback para relat√≥rio simulado
            report = generate_fallback_report(request.repo_name, request.analysis_type)
        
        # Criar job
        job_data = {
            "job_id": job_id,
            "repo_name": request.repo_name,
            "analysis_type": request.analysis_type,
            "branch_name": request.branch_name,
            "instrucoes_extras": request.instrucoes_extras,
            "status": "pending_approval",
            "message": "An√°lise inicial conclu√≠da. Aguardando aprova√ß√£o para implementa√ß√£o.",
            "progress": 25,
            "report": report,
            "created_at": get_current_timestamp(),
            "last_updated": get_current_timestamp()
        }
        
        jobs_storage[job_id] = job_data
        
        logger.info(f"Job {job_id} criado com sucesso")
        
        return {
            "job_id": job_id,
            "report": report,
            "status": "pending_approval",
            "message": "An√°lise conclu√≠da! Revise o relat√≥rio e aprove para prosseguir com a implementa√ß√£o."
        }
        
    except Exception as e:
        logger.error(f"Erro ao iniciar an√°lise: {e}")
        raise HTTPException(status_code=500, detail=f"Erro interno: {str(e)}")

@app.get("/status/{job_id}")
async def get_job_status(job_id: str):
    """Obt√©m o status de um job"""
    if job_id not in jobs_storage:
        raise HTTPException(status_code=404, detail="Job n√£o encontrado")
    
    job = jobs_storage[job_id]
    return {
        "job_id": job_id,
        "status": job["status"],
        "message": job["message"],
        "progress": job["progress"],
        "last_updated": job["last_updated"]
    }

@app.post("/update-job-status")
async def update_job_status(request: UpdateJobRequest, background_tasks: BackgroundTasks):
    """Atualiza status do job (aprovar/rejeitar)"""
    job_id = request.job_id
    
    if job_id not in jobs_storage:
        raise HTTPException(status_code=404, detail="Job n√£o encontrado")
    
    job = jobs_storage[job_id]
    
    if request.action == "approve":
        job.update({
            "status": "approved",
            "message": "An√°lise aprovada! Iniciando implementa√ß√£o...",
            "progress": 30,
            "last_updated": get_current_timestamp()
        })
        
        # Iniciar processo em background
        background_tasks.add_task(simulate_analysis_progress, job_id)
        
        return {
            "job_id": job_id,
            "status": "approved",
            "message": "Implementa√ß√£o iniciada em background"
        }
        
    elif request.action == "reject":
        job.update({
            "status": "rejected",
            "message": "An√°lise rejeitada pelo usu√°rio",
            "progress": 0,
            "last_updated": get_current_timestamp()
        })
        
        return {
            "job_id": job_id,
            "status": "rejected",
            "message": "An√°lise rejeitada"
        }
    
    else:
        raise HTTPException(status_code=400, detail="A√ß√£o inv√°lida. Use 'approve' ou 'reject'")

# =============================================================================
# ENDPOINTS DE POL√çTICAS
# =============================================================================

@app.post("/upload-policy")
async def upload_policy(
    name: str = Form(...),
    description: str = Form(...),
    file: UploadFile = File(...)
):
    """Upload de pol√≠tica da empresa"""
    try:
        # Validar arquivo
        if file.content_type not in ["text/plain", "application/pdf", "text/markdown"]:
            raise HTTPException(status_code=400, detail="Tipo de arquivo n√£o suportado")
        
        # Ler conte√∫do
        content = await file.read()
        
        # Salvar pol√≠tica
        policy_id = generate_job_id()
        policy_data = {
            "id": policy_id,
            "name": name,
            "description": description,
            "filename": file.filename,
            "content": content.decode("utf-8") if file.content_type.startswith("text") else content,
            "uploaded_at": datetime.now().isoformat()
        }
        
        policies_storage[policy_id] = policy_data
        
        return {
            "id": policy_id,
            "message": "Pol√≠tica enviada com sucesso!"
        }
        
    except Exception as e:
        logger.error(f"Erro no upload: {e}")
        raise HTTPException(status_code=500, detail=f"Erro no upload: {str(e)}")

@app.get("/policies")
async def get_policies():
    """Lista todas as pol√≠ticas"""
    return [
        {
            "id": policy["id"],
            "name": policy["name"],
            "description": policy["description"],
            "uploaded_at": policy["uploaded_at"]
        }
        for policy in policies_storage.values()
    ]

@app.delete("/policies/{policy_id}")
async def delete_policy(policy_id: str):
    """Remove uma pol√≠tica"""
    if policy_id not in policies_storage:
        raise HTTPException(status_code=404, detail="Pol√≠tica n√£o encontrada")
    
    del policies_storage[policy_id]
    return {"message": "Pol√≠tica removida com sucesso"}

# =============================================================================
# ENDPOINTS DE AN√ÅLISES AGENDADAS
# =============================================================================

@app.post("/scheduled-analyses")
async def create_scheduled_analysis(request: ScheduledAnalysisRequest):
    """Cria uma an√°lise agendada"""
    analysis_id = generate_job_id()
    
    analysis_data = {
        "id": analysis_id,
        "name": request.name,
        "repository": request.repository,
        "branch": request.branch,
        "analysis_type": request.analysis_type,
        "frequency": request.frequency,
        "custom_frequency": request.custom_frequency,
        "next_run": request.next_run or datetime.now().isoformat(),
        "created_at": datetime.now().isoformat(),
        "status": "active"
    }
    
    scheduled_analyses[analysis_id] = analysis_data
    
    return {
        "id": analysis_id,
        "message": "An√°lise agendada criada com sucesso!"
    }

@app.get("/scheduled-analyses")
async def get_scheduled_analyses():
    """Lista an√°lises agendadas"""
    return list(scheduled_analyses.values())

@app.delete("/scheduled-analyses/{analysis_id}")
async def delete_scheduled_analysis(analysis_id: str):
    """Remove an√°lise agendada"""
    if analysis_id not in scheduled_analyses:
        raise HTTPException(status_code=404, detail="An√°lise agendada n√£o encontrada")
    
    del scheduled_analyses[analysis_id]
    return {"message": "An√°lise agendada removida com sucesso"}

# =============================================================================
# FUN√á√ïES DE GERA√á√ÉO DE RELAT√ìRIOS
# =============================================================================

def generate_design_report(repo_name: str, analysis_result: dict) -> str:
    return f"""# üé® Relat√≥rio de An√°lise de Design - {repo_name}

## üìä Resumo Executivo
A an√°lise arquitetural do reposit√≥rio **{repo_name}** identificou oportunidades estrat√©gicas de melhoria na estrutura e organiza√ß√£o do c√≥digo.

## üîç Principais Descobertas

### 1. Arquitetura e Estrutura
- ‚úÖ **Organiza√ß√£o de pastas**: Estrutura base adequada
- ‚ö†Ô∏è **Modularidade**: Oportunidades de refatora√ß√£o identificadas
- üîß **Separa√ß√£o de responsabilidades**: Melhorias recomendadas

### 2. Padr√µes de Design
- **Princ√≠pios SOLID**: Aplica√ß√£o parcial detectada
- **Padr√µes GoF**: Recomenda√ß√£o para Strategy, Factory e Adapter
- **Clean Architecture**: Separa√ß√£o de camadas sugerida

### 3. Qualidade do C√≥digo
- **Complexidade ciclom√°tica**: Moderada
- **Manutenibilidade**: Boa com melhorias pontuais
- **Testabilidade**: Pode ser significativamente aprimorada

## üéØ Recomenda√ß√µes Priorit√°rias

1. **Implementar inje√ß√£o de depend√™ncias**
2. **Separar responsabilidades em m√≥dulos menores**
3. **Adicionar interfaces para desacoplamento**
4. **Melhorar cobertura de testes automatizados**
5. **Documentar arquitetura e decis√µes t√©cnicas**

## üöÄ Pr√≥ximos Passos

Se aprovado, o sistema ir√° automaticamente:
1. ‚ú® Aplicar refatora√ß√µes baseadas em melhores pr√°ticas
2. üìù Criar Pull Requests organizados por tema
3. üß™ Gerar testes automatizados
4. üìö Documentar todas as mudan√ßas implementadas

---
**Status**: ‚è≥ Aguardando aprova√ß√£o para prosseguir com implementa√ß√£o autom√°tica.
"""

def generate_test_report(repo_name: str, analysis_result: dict) -> str:
    return f"""# üß™ Relat√≥rio de An√°lise de Testes - {repo_name}

## üìà An√°lise de Cobertura Atual
An√°lise detalhada do reposit√≥rio **{repo_name}** para identificar gaps cr√≠ticos na cobertura de testes.

## üìä Situa√ß√£o Atual
- **Cobertura estimada**: 45%
- **Arquivos sem testes**: 12 arquivos cr√≠ticos
- **Fun√ß√µes descobertas**: 8 fun√ß√µes principais
- **Casos de borda identificados**: 15 cen√°rios

## üéØ Estrat√©gia de Testes Recomendada

### 1. Testes de Unidade
- ‚úÖ Fun√ß√µes principais do core business
- ‚úÖ Valida√ß√µes de entrada e sa√≠da
- ‚úÖ Tratamento robusto de erros e exce√ß√µes

### 2. Testes de Integra√ß√£o
- üîå APIs e endpoints cr√≠ticos
- üíæ Conex√µes com banco de dados
- üåê Integra√ß√£o com servi√ßos externos

### 3. Testes de Casos Extremos
- ‚ùå Valores nulos e vazios
- üìè Limites de entrada
- üí• Cen√°rios de falha e recupera√ß√£o

## üöÄ Plano de Implementa√ß√£o

### Prioridade Alta üî¥
- Fun√ß√µes cr√≠ticas de neg√≥cio
- Endpoints de API principais
- Valida√ß√µes de seguran√ßa

### Prioridade M√©dia üü°
- Utilit√°rios e helpers
- Formata√ß√µes e convers√µes
- Integra√ß√µes secund√°rias

### Prioridade Baixa üü¢
- Fun√ß√µes auxiliares
- Logs e monitoramento
- Configura√ß√µes

## üìã Pr√≥ximos Passos

Se aprovado, o sistema ir√°:
1. üß™ Gerar automaticamente testes unit√°rios
2. üìä Criar relat√≥rio de cobertura detalhado
3. üîß Configurar pipeline de testes
4. üìà Implementar m√©tricas de qualidade

---
**Meta**: Atingir 85% de cobertura de testes em 2 semanas.
"""

def generate_security_report(repo_name: str, analysis_result: dict) -> str:
    return f"""# üîí Relat√≥rio de An√°lise de Seguran√ßa - {repo_name}

## üõ°Ô∏è Resumo de Seguran√ßa
An√°lise de vulnerabilidades e boas pr√°ticas de seguran√ßa no reposit√≥rio **{repo_name}**.

## ‚ö†Ô∏è Vulnerabilidades Identificadas

### Cr√≠ticas üî¥
- **Exposi√ß√£o de credenciais**: Poss√≠veis chaves em arquivos de configura√ß√£o
- **Valida√ß√£o de entrada**: Falta sanitiza√ß√£o em formul√°rios
- **Autentica√ß√£o**: Implementa√ß√£o de autentica√ß√£o pode ser fortalecida

### Moderadas üü°
- **Logs de seguran√ßa**: Implementa√ß√£o incompleta de auditoria
- **Criptografia**: Algoritmos desatualizados em algumas funcionalidades
- **Depend√™ncias**: Packages com vulnerabilidades conhecidas

### Baixas üü¢
- **Headers de seguran√ßa**: Headers HTTP de seguran√ßa ausentes
- **Rate limiting**: Prote√ß√£o contra ataques de for√ßa bruta
- **CORS**: Configura√ß√£o muito permissiva

## üéØ Recomenda√ß√µes de Seguran√ßa

### 1. Prote√ß√£o de Dados
- Implementar criptografia end-to-end
- Configurar vault para secrets
- Aplicar princ√≠pio de menor privil√©gio

### 2. Autentica√ß√£o e Autoriza√ß√£o
- Multi-factor authentication (MFA)
- JSON Web Tokens (JWT) seguros
- Rate limiting personalizado

### 3. Monitoramento
- Logs de auditoria detalhados
- Alertas de atividade suspeita
- Monitoring de integridade

## üöÄ Plano de Mitiga√ß√£o

Se aprovado, o sistema ir√°:
1. üîê Aplicar patches de seguran√ßa automaticamente
2. üõ°Ô∏è Implementar valida√ß√µes robustas
3. üìä Configurar monitoramento de seguran√ßa
4. üìã Criar checklist de seguran√ßa para CI/CD

---
**Urg√™ncia**: Corre√ß√£o de vulnerabilidades cr√≠ticas em 48h.
"""

def generate_custom_report(repo_name: str, analysis_result: dict, analysis_type: str) -> str:
    return f"""# üîß Relat√≥rio de An√°lise Customizada - {repo_name}

## üìù Tipo de An√°lise: {analysis_type.title()}

An√°lise personalizada do reposit√≥rio **{repo_name}** focada em {analysis_type}.

## üîç Descobertas Principais

{analysis_result.get('report', 'An√°lise detalhada em progresso...')}

## üí° Recomenda√ß√µes

{' | '.join(analysis_result.get('recommendations', ['Aguardando an√°lise completa']))}

## üìä Estat√≠sticas
- **Arquivos analisados**: {analysis_result.get('files_analyzed', 'Calculando...')}
- **Issues encontrados**: {analysis_result.get('issues_found', 'Analisando...')}

## üöÄ Pr√≥ximos Passos

Se aprovado, o sistema implementar√° automaticamente as melhorias identificadas.

---
**Status**: Pronto para implementa√ß√£o.
"""

def generate_fallback_report(repo_name: str, analysis_type: str) -> str:
    return f"""# üìã Relat√≥rio de An√°lise - {repo_name}

## üîÑ An√°lise em Progresso

O sistema est√° processando a an√°lise do tipo **{analysis_type}** para o reposit√≥rio **{repo_name}**.

## ‚ö° Status Atual
- Conectando com reposit√≥rio
- Analisando estrutura de arquivos
- Executando verifica√ß√µes de qualidade

## üéØ Pr√≥ximos Passos
Aguarde a conclus√£o da an√°lise para ver recomenda√ß√µes detalhadas.

---
**Nota**: Esta √© uma an√°lise preliminar. O relat√≥rio completo ser√° gerado em breve.
"""

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)