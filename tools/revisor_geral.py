import os
from openai import OpenAI
from typing import Dict
from dotenv import load_dotenv

# Carregar variÃ¡veis de ambiente do arquivo .env
load_dotenv()

# Configurar cliente OpenAI
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
if not OPENAI_API_KEY:
    # Tentar obter de outras formas para compatibilidade
    OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')
    
if not OPENAI_API_KEY:
    raise ValueError(
        "âŒ A chave da API da OpenAI nÃ£o foi encontrada!\n"
        "Configure a variÃ¡vel de ambiente OPENAI_API_KEY ou adicione no arquivo .env:\n"
        "OPENAI_API_KEY=sua_chave_aqui"
    )

print(f"âœ… OpenAI API configurada (chave: {OPENAI_API_KEY[:10]}...)")
openai_client = OpenAI(api_key=OPENAI_API_KEY)

def carregar_prompt(tipo_analise: str) -> str:
    """Carrega o conteÃºdo do arquivo de prompt correspondente."""
    # Ajustar caminho para funcionar tanto no desenvolvimento quanto em produÃ§Ã£o
    base_dir = os.path.dirname(os.path.abspath(__file__))
    caminho_prompt = os.path.join(base_dir, 'prompt', f'{tipo_analise}.md')
    
    try:
        with open(caminho_prompt, 'r', encoding='utf-8') as f:
            content = f.read()
            print(f"âœ… Prompt carregado: {caminho_prompt}")
            return content
    except FileNotFoundError:
        print(f"âŒ Arquivo de prompt nÃ£o encontrado: {caminho_prompt}")
        # Tentar caminho alternativo (para compatibilidade)
        caminho_alternativo = os.path.join(base_dir, 'prompts', f'{tipo_analise}.md')
        try:
            with open(caminho_alternativo, 'r', encoding='utf-8') as f:
                content = f.read()
                print(f"âœ… Prompt carregado (caminho alternativo): {caminho_alternativo}")
                return content
        except FileNotFoundError:
            raise ValueError(f"Arquivo de prompt para '{tipo_analise}' nÃ£o encontrado em:\n- {caminho_prompt}\n- {caminho_alternativo}")

def executar_analise_llm(
    tipo_analise: str,
    codigo: str,
    analise_extra: str = "",
    model_name: str = "gpt-4.1",  # Modelo mais econÃ´mico por padrÃ£o
    max_token_out: int = 3000
) -> str:
    """
    Executa anÃ¡lise de cÃ³digo usando a API do ChatGPT
    
    Args:
        tipo_analise: Tipo de anÃ¡lise (design, pentest, seguranca, terraform)
        codigo: CÃ³digo fonte para analisar
        analise_extra: InstruÃ§Ãµes extras do usuÃ¡rio
        model_name: Modelo da OpenAI a usar
        max_token_out: MÃ¡ximo de tokens na resposta
    
    Returns:
        Resultado da anÃ¡lise em formato markdown
    """
    
    print(f"ğŸ” Iniciando anÃ¡lise {tipo_analise} com modelo {model_name}")
    
    try:
        # Carregar prompt do sistema
        prompt_sistema = carregar_prompt(tipo_analise)
        
        # Preparar mensagens
        mensagens = [
            {"role": "system", "content": prompt_sistema},
            {"role": "user", "content": f"CÃ“DIGO PARA ANÃLISE:\n\n{codigo}"}
        ]
        
        # Adicionar instruÃ§Ãµes extras se fornecidas
        if analise_extra and analise_extra.strip():
            mensagens.append({
                "role": "user", 
                "content": f"INSTRUÃ‡Ã•ES EXTRAS DO USUÃRIO:\n{analise_extra}"
            })
        else:
            mensagens.append({
                "role": "user",
                "content": "Nenhuma instruÃ§Ã£o extra fornecida pelo usuÃ¡rio."
            })
        
        print(f"ğŸ“¤ Enviando requisiÃ§Ã£o para OpenAI...")
        print(f"ğŸ“Š Tokens estimados: ~{len(codigo)//4} (cÃ³digo) + {len(prompt_sistema)//4} (prompt)")
        
        # Fazer chamada para a API
        response = openai_client.chat.completions.create(
            model=model_name,
            messages=mensagens,
            temperature=0.3,  # Reduzir para respostas mais consistentes
            max_tokens=max_token_out,
            top_p=0.9,
            frequency_penalty=0.0,
            presence_penalty=0.0
        )
        
        # Extrair resposta
        conteudo_resposta = response.choices[0].message.content.strip()
        
        # Log de sucesso
        tokens_usados = response.usage.total_tokens if response.usage else "N/A"
        print(f"âœ… AnÃ¡lise concluÃ­da! Tokens usados: {tokens_usados}")
        print(f"ğŸ“ Tamanho da resposta: {len(conteudo_resposta)} caracteres")
        
        return conteudo_resposta
        
    except Exception as e:
        error_msg = f"Erro ao comunicar com a OpenAI para anÃ¡lise '{tipo_analise}': {str(e)}"
        print(f"âŒ {error_msg}")
        
        # Fornecer informaÃ§Ãµes de debug Ãºteis
        if "rate_limit" in str(e).lower():
            error_msg += "\nğŸ’¡ Dica: Aguarde alguns minutos antes de tentar novamente (rate limit)."
        elif "insufficient_quota" in str(e).lower():
            error_msg += "\nğŸ’¡ Dica: Verifique se hÃ¡ crÃ©ditos suficientes na sua conta OpenAI."
        elif "invalid_api_key" in str(e).lower():
            error_msg += "\nğŸ’¡ Dica: Verifique se a chave OPENAI_API_KEY estÃ¡ correta."
        
        raise RuntimeError(error_msg) from e

def test_openai_connection():
    """Testa a conexÃ£o com a API da OpenAI"""
    try:
        print("ğŸ§ª Testando conexÃ£o com OpenAI...")
        response = openai_client.chat.completions.create(
            model="gpt-4.1",
            messages=[{"role": "user", "content": "Test"}],
            max_tokens=5
        )
        print("âœ… ConexÃ£o com OpenAI funcionando!")
        return True
    except Exception as e:
        print(f"âŒ Erro na conexÃ£o com OpenAI: {e}")
        return False

if __name__ == "__main__":
    # Teste bÃ¡sico quando executado diretamente
    print("ğŸš€ Testando configuraÃ§Ã£o do revisor geral...")
    
    if test_openai_connection():
        print("âœ… Tudo configurado corretamente!")
    else:
        print("âŒ HÃ¡ problemas na configuraÃ§Ã£o. Verifique a chave da API.")
    
    # Listar prompts disponÃ­veis
    base_dir = os.path.dirname(os.path.abspath(__file__))
    prompt_dir = os.path.join(base_dir, 'prompt')
    if os.path.exists(prompt_dir):
        prompts = [f.replace('.md', '') for f in os.listdir(prompt_dir) if f.endswith('.md')]
        print(f"ğŸ“‹ Prompts disponÃ­veis: {prompts}")
    else:
        print("âš ï¸ DiretÃ³rio de prompts nÃ£o encontrado")